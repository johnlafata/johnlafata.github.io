 # VKS Network Requirements

An important aspect to understand before enabling workload management (aka creating a Supervisor Cluster) is the networking used in vks.

A example of the networks (portgroups) involved and their roles in a vSphere Kubernetes Service (VKS) deployment is shown below: 

| Subnet  |	Comment |
|---------|---------|
| 192.168.86.0/24 | Management network (vCenter, ESXi, Avi controller), Supervisor Control Plane VMS |
| 192.168.84.0/24 | Frontend/load balancer network (Avi VIPs) |
| 192.168.85.0/24 | Workload network (kubernetes deployments |


There are 3 important portgroups involved in the networking of a vSphere Kubernetes Service (VKS) deployment:

* **Management Portgroup**: Used for management traffic, including vSphere Client access and vCenter Server communication.
* **Workload Portgroup**: Used for Kubernetes workloads and services, allowing communication between pods and services.
* **Front End(VIP) Portgroup**:  Used for load balancing and external access to Kubernetes services, typically configured with a load balancer like Avi or HAProxy.

_Special Considerations for Network Portgroups_

When configuring the required portgroups for VKS, consider these important factors:

**Management Portgroup:**
- Must be configured with sufficient bandwidth for control plane operations
- Should be isolated from general VM traffic for security
- Requires stable IP addressing and DNS resolution for vCenter components

**Workload Portgroup:**
- Should be sized appropriately for pod-to-pod communication bandwidth
- Must have connectivity between both sites of the stretched cluster
- Consider implementing network QoS to prioritize critical workload traffic
- Plan IP addressing carefully to accommodate pod and service CIDR ranges

**Front End (VIP) Portgroup:**
- Must be accessible from client networks that need to consume Kubernetes services
- Requires sufficient public IP addresses for externally exposed services
- Should be configured with appropriate security controls (firewall rules)
- May require specific VLAN configurations for load balancer integration
- Consider latency between sites when configuring load balancer health checks

All portgroups should have consistent configuration across both sites of the stretched cluster to ensure proper failover in case of site outage.

_VKS Component Distribution Across Network Portgroups_

Each network portgroup in a VKS deployment serves specific components:

**Management Portgroup Components:**
- vSphere Control Plane VMs (Supervisor Control Plane)
- Kubernetes API server endpoints
- etcd database instances for cluster state
- vSphere Pod Service components
- Authentication and authorization services

**Workload Portgroup Components:**
- Tanzu Kubernetes Grid (TKG) workload clusters
- Namespace workloads (pods, deployments, etc.)
- Inter-pod communication pathways
- ClusterIP services
- Container runtime networking components
- CNI (Container Network Interface) components

**Front End (VIP) Portgroup Components:**
- Load balancer controller instances
- Service type LoadBalancer VIPs
- Ingress controller endpoints
- External-facing Kubernetes API endpoints
- NodePort service access points
- External DNS integration components

For stretched cluster deployments, these components are distributed across both sites to ensure high availability and resilience in case of site failure.

## Firewall Considerations for VKS Network Portgroups

When implementing a VKS environment, proper firewall configuration is critical to ensure secure communication between the different network portgroups while maintaining required connectivity.

### Required Firewall Rules Between Portgroups

**Management to Workload Network:**
- TCP 6443: Allow Kubernetes API server traffic
- TCP 443: vCenter Server to workload VMs
- TCP/UDP 53: DNS resolution services
- TCP 22: SSH access for troubleshooting (can be restricted)
- TCP 8080/9090: Metrics and monitoring services
- TCP 2379-2380: etcd client and peer communication

**Management to Front End Network:**
- TCP 443: Management access to load balancer admin interfaces
- TCP 22: SSH access to load balancer controllers
- TCP 5556: AVI Controller to Service Engine communication (if using NSX ALB)
- ICMP: Health check and monitoring

**Workload to Front End Network:**
- TCP 80/443: HTTP/HTTPS traffic to load balanced services
- TCP 30000-32767: NodePort service range
- TCP 20000-30000: Additional ports for application-specific services
- UDP as required by specific applications

**Front End to External Networks:**
- TCP 80/443: Inbound HTTP/HTTPS traffic from clients
- Application-specific ports as needed for external access

### Firewall Best Practices for VKS

- Implement micro-segmentation where possible to limit lateral movement
- Use security groups or distributed firewalls for granular control
- Log all denied traffic for security analysis and troubleshooting
- Consider implementing rate limiting on public-facing services
- Regularly audit and update firewall rules based on actual traffic patterns
- For stretched clusters, ensure consistent firewall configuration across sites
- Apply the principle of least privilege, only opening required ports

Proper firewall configuration between these network segments helps maintain security while ensuring all VKS components can communicate as needed for normal operation.